{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References \n",
    "## Source : \n",
    "        [Twitter Sentiment Analysis](https://datahack.analyticsvidhya.com/contest/practice-problem-twitter-sentiment-analysis/)\n",
    "## Resources :\n",
    "1. https://www.geeksforgeeks.org/twitter-sentiment-analysis-using-python/\n",
    "2. https://chrisalbon.com/python/data_wrangling/pandas_apply_operations_to_dataframes/\n",
    "3. https://www.analyticsvidhya.com/blog/2014/11/text-data-cleaning-steps-python/\n",
    "4. https://machinelearningmastery.com/clean-text-machine-learning-python/\n",
    "5. https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a\n",
    "6. http://scikit-learn.org/stable/modules/cross_validation.html\n",
    "7. http://scikit-learn.org/stable/modules/pipeline.html\n",
    "8. http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB  # Naive Bayes\n",
    "from sklearn.naive_bayes import BernoulliNB  # Bernoulli Naive Bayes\n",
    "from sklearn.metrics import precision_recall_fscore_support as pr\n",
    "from sklearn.linear_model import SGDClassifier  # Lineaer Classifier\n",
    "from sklearn.model_selection import GridSearchCV  # GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier #Random Forest\n",
    "from sklearn.tree import DecisionTreeClassifier # Decision Tree \n",
    "from sklearn.svm import LinearSVC # Support Vector Classification\n",
    "from sklearn.neural_network import MLPClassifier # Multi Layer Neural Network\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to update my nltk data folder\n",
    "# nltk.download()\n",
    "\n",
    "pd.set_option('max_colwidth', 280)\n",
    "dataPath = \"data\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Steps : Data Cleaning, Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingDataPath = dataPath + \"train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(trainingDataPath,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "apostrophe = { \n",
    "    \"'m\":\"am\",\"'d\":\"had\",\"'s\":\"is\",\"'ve\":\"have\",\"'ll\":\"will\",\"'re\":\"are\",\"'t\":\"not\"\n",
    "}\n",
    "# special cases are can't won't ain't\n",
    "# made using list under https://www.panopy.com/iphone/secret-ada/cracking-a-cipher.html\n",
    "\n",
    "# Stop words in english Language\n",
    "stop_words = stopwords.words('english')\n",
    "# print(stop_words)\n",
    "# Stemming Engine\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apostropheCleaner(x):\n",
    "    x = x.lower()\n",
    "    # Step 1 : removing apostrophe\n",
    "    words = x.split()\n",
    "    reformed = []\n",
    "    flag = False\n",
    "    for word in words:\n",
    "        flag = False\n",
    "        for k in apostrophe:\n",
    "            if k in word:\n",
    "                flag = True\n",
    "                if k == \"'t\":\n",
    "                    # for type : can't,won't,ain't\n",
    "                    if word == \"can't\":\n",
    "                        reformed.append(\"can not\")\n",
    "                    elif word == \"won't\":\n",
    "                        reformed.append(\"will not\")\n",
    "                    elif word == \"ain't\":\n",
    "                        reformed.append(\"is not\")\n",
    "                    else:\n",
    "                        reformed.append(word.split(\"'\")[0][:-1]+\" \"+apostrophe[k])\n",
    "                else:\n",
    "                    reformed.append(word.split(\"'\")[0]+\" \"+apostrophe[k])\n",
    "                break\n",
    "        if not flag:\n",
    "            reformed.append(word)\n",
    "    return \" \".join(reformed)\n",
    "\n",
    "def linkCleaner(x):\n",
    "    # Step 2: URL removal\n",
    "    # removing url,usernames and hashtag\n",
    "    return re.sub(r\"http\\S+|@\\S+\", \"\", x)\n",
    "    \n",
    "def hashtagExtract(x):    \n",
    "    return \" \".join(set(re.findall(r\"#(\\w+)\", x)))\n",
    "    \n",
    "def wordCleaner(x):\n",
    "    # remove the hadhtags that remained with the sentence\n",
    "    # x = re.sub(r\"#\\S+\", \"\", x)\n",
    "    \n",
    "    # # Step 3: Removing Punctuation\n",
    "    # tokens = word_tokenize(reform)\n",
    "    # words = [w for w in tokens if w.isalpha()]\n",
    "    \n",
    "    # # Step 4: Stemming Words\n",
    "    # stemmed = [stemmer.stem(word) for word in words]\n",
    "    \n",
    "    # # Step 5: Removing Stop Words\n",
    "    # words = [w for w in stemmed if not w in stop_words]\n",
    "    \n",
    "    # Combining Step 3,4,5\n",
    "    tokens = word_tokenize(x)\n",
    "    words = []\n",
    "    for w in tokens:\n",
    "        if w.isalpha() and w not in stop_words:\n",
    "            # words.append(stemmer.stem(w))   //// ignoring stemming for now\n",
    "            words.append(w)\n",
    "    x = \" \".join(words)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cleanedTweet'] = data['tweet'].transform(apostropheCleaner)\n",
    "\n",
    "data['cleanedTweet'] = data['cleanedTweet'].transform(linkCleaner)\n",
    "\n",
    "data['hastag'] = data['cleanedTweet'].transform(hashtagExtract)\n",
    "\n",
    "data['cleanedTweet'] = data['cleanedTweet'].transform(wordCleaner)\n",
    "\n",
    "# data[data['label'] == 1]\n",
    "\n",
    "features = data['cleanedTweet']\n",
    "label = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31962,)\n",
      "0                                                              father dysfunctional selfish drags kids dysfunction run\n",
      "1                                        thanks lyft credit use cause offer wheelchair vans pdx disapointed getthanked\n",
      "2                                                                                                       bihday majesty\n",
      "3                                                                                             model love u take u time\n",
      "4                                                                                        factsguide society motivation\n",
      "5                                                huge fan fare big talking leave chaos pay disputes get allshowandnogo\n",
      "6                                                                                                     camping tomorrow\n",
      "7                               next school year year think school exams hate imagine actorslife revolutionschool girl\n",
      "8                                                          love land allin cavs champions cleveland clevelandcavaliers\n",
      "9                                                                                                              welcome\n",
      "10                                        ireland consumer price index mom climbed previous may blog silver gold forex\n",
      "11       selfish orlando standwithorlando pulseshooting orlandoshooting biggerproblems selfish heabreaking values love\n",
      "12                                                                                      get see daddy today gettingfed\n",
      "13                                                                    cnn calls michigan middle school wall chant tcot\n",
      "14                                comment australia opkillingbay seashepherd helpcovedolphins thecove helpcovedolphins\n",
      "15                                                                                      ouch junior junior yugyoem omg\n",
      "16                                                                                    thankful paner thankful positive\n",
      "17                                                                                                       retweet agree\n",
      "18                                                                friday smiles around via ig user cookies make people\n",
      "19                                                                                  know essential oils made chemicals\n",
      "20                                     people blaming ha conceded goal fat rooney gave away free kick knowing bale hit\n",
      "21                                                              sad little badday coneofshame cats pissed funny laughs\n",
      "22                                                         product day happy man wine tool weekend time open amp drink\n",
      "23                                                                                              lumpy says prove lumpy\n",
      "24                                                                         tgif ff gamedev indiedev indiegamedev squad\n",
      "25                                                              beautiful sign vendor upsideofflorida shopalyssas love\n",
      "26                                                   smiles media pressconference antalya turkey sunday throwback love\n",
      "27                                                                            great panel mediatization public service\n",
      "28                                                                                                    happy father day\n",
      "29                         people went nightclub good night man actions means people lost families forever rip orlando\n",
      "                                                             ...                                                      \n",
      "31932                                                                                                     thanks gemma\n",
      "31933                             judd amp homophobic freemilo milo freemilo milo freemilo milo freemilo milo freemilo\n",
      "31934                                                                       lady banned kentucky mall jcpenny kentucky\n",
      "31935                               ugh trying enjoy happy hour drink amp talks politics bar guess discussing ugh hour\n",
      "31936                                            want know live life things make happy less things make unhappy simple\n",
      "31937                                                                                                      love island\n",
      "31938                                                 fav actor vijaysethupathi fav actress fav director one film wait\n",
      "31939                                                                                           whew productive friday\n",
      "31940                                                                                                          finally\n",
      "31941                                    passed first year uni yay love pass unistudent photographystudent ucs soproud\n",
      "31942                                                                               week flying humpday wednesday kamp\n",
      "31943                                                                  modeling photoshoot friday yay model follow emo\n",
      "31944                                                                  surrounded people love even deserve yet hateful\n",
      "31945                                                                            feel like dog summer hot help sun day\n",
      "31946                                                             omfg offended mailbox proud mailboxpride liberalisme\n",
      "31947                                                                           balls hashtag say weasel lumpy dipshit\n",
      "31948                                                                                   makes ask anybody oh thank god\n",
      "31949                            hear one new songs go katie ellie youtube original music song relationship songwriter\n",
      "31950                                                                    try us stop good time goldenretriever animals\n",
      "31951                                                                           posted new blog secondlife lonely neko\n",
      "31952                                                                                                         went far\n",
      "31953                                 good morning instagram shower water berlin berlincitygirl girl newyork genf bern\n",
      "31954                                                                  holiday bull dominate bull direct whatever want\n",
      "31955                                                              less weeks ibiza bringiton mallorca holidays summer\n",
      "31956                                                                     fishing tomorrow carnt wait first time years\n",
      "31957                                                                                                    ate isz youuu\n",
      "31958                    see nina turner airwaves trying wrap mantle genuine hero like shirley chisolm shame imwithher\n",
      "31959                                                                  listening sad songs monday morning otw work sad\n",
      "31960                                                                  sikh temple vandalised calgary wso condemns act\n",
      "31961                                                                                                     thank follow\n",
      "Name: cleanedTweet, Length: 31962, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)\n",
    "# print(features)\n",
    "\n",
    "# print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data using Sklearn Model Selection, this should give us better results for cross valication\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(features, label, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25569,) (25569,) (6393,) (6393,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,Y_train.shape,X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remember \n",
    "    When data set is very skewed like in current scenario where there are very low number of `class 1` and very large number of `class 0`, \n",
    "    rather than calculating accuracy, we should be measuring the model using f1 Score, which is calculated using Precision and Recall\n",
    "### Precision :\n",
    "    * High Precision means low false positive\n",
    "    * It means low wrong prediction for class 0\n",
    "### Recall :\n",
    "    * High Recall means low false negative\n",
    "    * It means low wrong prediction for class 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.7073955   0.67779633  0.66777963  0.67343486  0.69666667]\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "text_clf_nb = Pipeline([\n",
    "                        ('vect', CountVectorizer(ngram_range=(1, 2))),\n",
    "                        ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "                        ('clf_nb', MultinomialNB(alpha = 0.01))\n",
    "                       ])\n",
    "print(cross_val_score(text_clf_nb,X_train,Y_train,cv=5,scoring='f1'))\n",
    "text_clf_nb = text_clf_nb.fit(X_train,Y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified as Class 1 : 308\n",
      "Total Actual Class 1 : 478\n",
      "Values for Naive Bayes :  Precision -> 0.863636363636  Recall-> 0.556485355649  F1score-> 0.676844783715\n"
     ]
    }
   ],
   "source": [
    "predicted_nb = text_clf_nb.predict(X_test)\n",
    "print(\"Classified as Class 1 :\", sum(predicted_nb))\n",
    "print(\"Total Actual Class 1 :\",sum(Y_test))\n",
    "# F1 Score, Precision, Recall\n",
    "Precision, Recall, F1score, Support = pr(Y_test, predicted_nb, average='binary', pos_label=1,beta=1.0)\n",
    "print(\"Values for Naive Bayes : \",\"Precision ->\",Precision,\" Recall->\",Recall,\" F1score->\",F1score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear CLassifer\n",
    "text_clf_linearClassifier = Pipeline([\n",
    "                                        ('vect', CountVectorizer()), \n",
    "                                        ('tfidf', TfidfTransformer()), \n",
    "                                        ('clf-lc', SGDClassifier(loss='perceptron', penalty='elasticnet', alpha=0.0001, max_iter=1000, tol=0.001))\n",
    "                                    ])\n",
    "text_clf_linearClassifier = text_clf_linearClassifier.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified as Class 1 : 420\n",
      "Total Actual Class 1 : 478\n",
      "Values for Linear Classifier :  Precision -> 0.602380952381  Recall-> 0.529288702929  F1score-> 0.563474387528\n"
     ]
    }
   ],
   "source": [
    "predicted_linearClassifier = text_clf_linearClassifier.predict(X_test)\n",
    "print(\"Classified as Class 1 :\", sum(predicted_linearClassifier))\n",
    "print(\"Total Actual Class 1 :\",sum(Y_test))\n",
    "# F1 Score, Precision, Recall\n",
    "Precision, Recall, F1score, Support = pr(Y_test, predicted_linearClassifier, average='binary', pos_label=1,beta=1.0)\n",
    "print(\"Values for Linear Classifier : \",\"Precision ->\",Precision,\" Recall->\",Recall,\" F1score->\",F1score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "clf_rf = Pipeline([\n",
    "                        ('vect', CountVectorizer()),\n",
    "                        ('tfidf', TfidfTransformer()),\n",
    "                        ('clf_rf', RandomForestClassifier(n_estimators=100, max_features=2))\n",
    "                 ])\n",
    "clf_rf = clf_rf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified as Class 1 : 167\n",
      "Total Actual Class 1 : 478\n",
      "Values for Random Forest :  Precision -> 0.964071856287  Recall-> 0.336820083682  F1score-> 0.499224806202\n"
     ]
    }
   ],
   "source": [
    "predicted_rf = clf_rf.predict(X_test)\n",
    "print(\"Classified as Class 1 :\", sum(predicted_rf))\n",
    "print(\"Total Actual Class 1 :\",sum(Y_test))\n",
    "# F1 Score, Precision, Recall\n",
    "Precision, Recall, F1score, Support = pr(Y_test, predicted_rf, average='binary', pos_label=1,beta=1.0)\n",
    "print(\"Values for Random Forest : \",\"Precision ->\",Precision,\" Recall->\",Recall,\" F1score->\",F1score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.56929955,  0.64619883,  0.59167951,  0.59411765,  0.6185567 ])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DecisionTreeClassifier\n",
    "clf_dt = Pipeline([\n",
    "                        ('vect', CountVectorizer()),\n",
    "                        ('tfidf', TfidfTransformer()),\n",
    "                        ('clf_dt', DecisionTreeClassifier())\n",
    "                 ])\n",
    "print(cross_val_score(clf_dt,X_train,Y_train,cv=5,scoring='f1'))\n",
    "clf_dt = clf_dt.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified as Class 1 : 415\n",
      "Total Actual Class 1 : 478\n",
      "Values for Random Forest :  Precision -> 0.964071856287  Recall-> 0.336820083682  F1score-> 0.499224806202\n"
     ]
    }
   ],
   "source": [
    "predicted_dt = clf_dt.predict(X_test)\n",
    "print(\"Classified as Class 1 :\", sum(predicted_dt))\n",
    "print(\"Total Actual Class 1 :\",sum(Y_test))\n",
    "# F1 Score, Precision, Recall\n",
    "Precision, Recall, F1score, Support = pr(Y_test, predicted_rf, average='binary', pos_label=1,beta=1.0)\n",
    "print(\"Values for Random Forest : \",\"Precision ->\",Precision,\" Recall->\",Recall,\" F1score->\",F1score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.7217806   0.72281776  0.7073955   0.68454259  0.70684039]\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naive Bayes\n",
    "clf_bnb = Pipeline([\n",
    "                        ('vect', CountVectorizer(ngram_range=(1,2))),\n",
    "                        ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "                        ('clf_bnb', BernoulliNB(alpha = 0.0117))\n",
    "                 ])\n",
    "print(cross_val_score(clf_bnb,X_train,Y_train,cv=5,scoring='f1'))\n",
    "clf_bnb = clf_bnb.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified as Class 1 : 372\n",
      "Total Actual Class 1 : 478\n",
      "Values for Bernoulli Naive Bayes :  Precision -> 0.790322580645  Recall-> 0.615062761506  F1score-> 0.691764705882\n"
     ]
    }
   ],
   "source": [
    "predicted_bnb = clf_bnb.predict(X_test)\n",
    "print(\"Classified as Class 1 :\", sum(predicted_bnb))\n",
    "print(\"Total Actual Class 1 :\",sum(Y_test))\n",
    "# F1 Score, Precision, Recall\n",
    "Precision, Recall, F1score, Support = pr(Y_test, predicted_bnb, average='binary', pos_label=1,beta=1.0)\n",
    "print(\"Values for Bernoulli Naive Bayes : \",\"Precision ->\",Precision,\" Recall->\",Recall,\" F1score->\",F1score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Classification\n",
    "clf_svc = Pipeline([\n",
    "                        ('vect', CountVectorizer()),\n",
    "                        ('tfidf', TfidfTransformer()),\n",
    "                        ('clf_svc', LinearSVC())\n",
    "                 ])\n",
    "clf_svc = clf_svc.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified as Class 1 : 305\n",
      "Total Actual Class 1 : 478\n",
      "Values for Bernoulli Naive Bayes :  Precision -> 0.865573770492  Recall-> 0.55230125523  F1score-> 0.674329501916\n"
     ]
    }
   ],
   "source": [
    "predicted_svc = clf_svc.predict(X_test)\n",
    "print(\"Classified as Class 1 :\", sum(predicted_svc))\n",
    "print(\"Total Actual Class 1 :\",sum(Y_test))\n",
    "# F1 Score, Precision, Recall\n",
    "Precision, Recall, F1score, Support = pr(Y_test, predicted_svc, average='binary', pos_label=1,beta=1.0)\n",
    "print(\"Values for Bernoulli Naive Bayes : \",\"Precision ->\",Precision,\" Recall->\",Recall,\" F1score->\",F1score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-layer Perceptron classifier (Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Classification\n",
    "clf_nn = Pipeline([\n",
    "                        ('vect', CountVectorizer()),\n",
    "                        ('tfidf', TfidfTransformer()),\n",
    "                        ('clf_nn', MLPClassifier(hidden_layer_sizes=20))\n",
    "                 ])\n",
    "clf_nn = clf_nn.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified as Class 1 : 419\n",
      "Total Actual Class 1 : 478\n",
      "Values for Bernoulli Naive Bayes :  Precision -> 0.692124105012  Recall-> 0.606694560669  F1score-> 0.646599777035\n"
     ]
    }
   ],
   "source": [
    "predicted_nn = clf_nn.predict(X_test)\n",
    "print(\"Classified as Class 1 :\", sum(predicted_nn))\n",
    "print(\"Total Actual Class 1 :\",sum(Y_test))\n",
    "# F1 Score, Precision, Recall\n",
    "Precision, Recall, F1score, Support = pr(Y_test, predicted_nn, average='binary', pos_label=1,beta=1.0)\n",
    "print(\"Values for Bernoulli Naive Bayes : \",\"Precision ->\",Precision,\" Recall->\",Recall,\" F1score->\",F1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch \n",
    "\n",
    "It is used for finding the best fit of parameter for the defined estimator (predictor/model/classifier) from a range defined under param_grid for the corresponding estimator.\n",
    "\n",
    "The Following are the parameters defined for GridSearch :\n",
    "*   Defined to run on multi core\n",
    "*   Uses f1 scoring\n",
    "*   4-fold cross validation\n",
    "*   It is resistent to model failures (if it does) for any combination of parameters within the range it is searching for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch For Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing the Parameters for setting up parameters for `param_grid`\n",
    "# text_clf_nb.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'vect__ngram_range': [(1, 3), (1, 2)],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf_nb__alpha': (1e-2, 1e-3, 0.015)\n",
    "}\n",
    "gs_clf_nb = GridSearchCV(text_clf_nb, param_grid, n_jobs=-1, cv=4, scoring='f1', error_score=np.NaN, refit=True)\n",
    "gs_clf_nb = gs_clf_nb.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.687984527233 {'clf_nb__alpha': 0.01, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "# print(gs_clf.best_score_,gs_clf.best_params_,gs_clf.best_estimator_)\n",
    "print(gs_clf_nb.best_score_,gs_clf_nb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified as Class 1 : 308\n",
      "Total Actual Class 1 : 478\n"
     ]
    }
   ],
   "source": [
    "# As refit is True, the estimators are already trained with the best possible parameters within the defined range \n",
    "# and we can use predict fuction directly \n",
    "predicted_gs_clf_nb = gs_clf_nb.predict(X_test)\n",
    "print(\"Classified as Class 1 :\", sum(predicted_gs_clf_nb))\n",
    "print(\"Total Actual Class 1 :\",sum(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values for Best Parameters from Grid Search Naive Bayes :  Precision -> 0.863636363636  Recall-> 0.556485355649  F1score-> 0.676844783715\n"
     ]
    }
   ],
   "source": [
    "# F1 Score, Precision, Recall\n",
    "Precision, Recall, F1score, Support = pr(Y_test, predicted_gs_clf_nb, average='binary', pos_label=1,beta=1.0)\n",
    "print(\"Values for Best Parameters from Grid Search Naive Bayes : \",\"Precision ->\",Precision,\" Recall->\",Recall,\" F1score->\",F1score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch For Bernoulli Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing the Parameters for setting up parameters for `param_grid`\n",
    "# clf_bnb.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'vect__ngram_range': [(1, 2),],\n",
    "    'tfidf__use_idf': (True,),\n",
    "    'clf_bnb__alpha': (0.0117, 0.01175, 0.0118)\n",
    "}\n",
    "gs_clf_bnb = GridSearchCV(clf_bnb, param_grid, n_jobs=-1, cv=4, scoring='f1', error_score=np.NaN, refit=True)\n",
    "gs_clf_bnb = gs_clf_bnb.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.710920222142 {'clf_bnb__alpha': 0.0117, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "# print(gs_clf.best_score_,gs_clf.best_params_,gs_clf.best_estimator_)\n",
    "print(gs_clf_bnb.best_score_,gs_clf_bnb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified as Class 1 : 372\n",
      "Total Actual Class 1 : 478\n"
     ]
    }
   ],
   "source": [
    "# As refit is True, the estimators are already trained with the best possible parameters within the defined range \n",
    "# and we can use predict fuction directly \n",
    "predicted_gs_clf_bnb = gs_clf_bnb.predict(X_test)\n",
    "print(\"Classified as Class 1 :\", sum(predicted_gs_clf_bnb))\n",
    "print(\"Total Actual Class 1 :\",sum(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values for Best Parameters from Grid Search Naive Bayes :  Precision -> 0.790322580645  Recall-> 0.615062761506  F1score-> 0.691764705882\n"
     ]
    }
   ],
   "source": [
    "# F1 Score, Precision, Recall\n",
    "Precision, Recall, F1score, Support = pr(Y_test, predicted_gs_clf_bnb, average='binary', pos_label=1,beta=1.0)\n",
    "print(\"Values for Best Parameters from Grid Search Naive Bayes : \",\"Precision ->\",Precision,\" Recall->\",Recall,\" F1score->\",F1score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch For Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of parameters for Linear Classifer \n",
    "# text_clf_linearClassifier.get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'vect__ngram_range': [(1, 2),(1,3)],\n",
    "    'tfidf__use_idf': (True,),\n",
    "    'clf-lc__alpha': (0.015,0.02),\n",
    "    'clf-lc__loss': ('perceptron',),\n",
    "    'clf-lc__max_iter': (1000,),\n",
    "    'clf-lc__penalty': ('l2',),\n",
    "    'clf-lc__tol': (0.001,),\n",
    "}\n",
    "# using just one core as CPU percent usage was very high \n",
    "gs_linearClassifier = GridSearchCV(text_clf_linearClassifier, param_grid, n_jobs=1, cv=4, scoring='f1', error_score=np.NaN, refit=True)\n",
    "gs_linearClassifier = gs_linearClassifier.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.644580739072 {'clf-lc__alpha': 0.02, 'clf-lc__loss': 'perceptron', 'clf-lc__max_iter': 1000, 'clf-lc__penalty': 'l2', 'clf-lc__tol': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 3)}\n"
     ]
    }
   ],
   "source": [
    "# print(gs_clf.best_score_,gs_clf.best_params_,gs_clf.best_estimator_)\n",
    "print(gs_linearClassifier.best_score_,gs_linearClassifier.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified as Class 1 : 535\n",
      "Total Actual Class 1 : 478\n"
     ]
    }
   ],
   "source": [
    "# As refit is True, the estimators are already trained with the best possible parameters within the defined range \n",
    "# and we can use predict fuction directly \n",
    "predicted_gs_linearClassifier = gs_linearClassifier.predict(X_test)\n",
    "print(\"Classified as Class 1 :\", sum(predicted_gs_linearClassifier))\n",
    "print(\"Total Actual Class 1 :\",sum(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values for Best Parameters from Grid Search Linear Classifier :  Precision -> 0.629906542056  Recall-> 0.705020920502  F1score-> 0.665350444225\n"
     ]
    }
   ],
   "source": [
    "# F1 Score, Precision, Recall\n",
    "Precision, Recall, F1score, Support = pr(Y_test, predicted_gs_linearClassifier, average='binary', pos_label=1,beta=1.0)\n",
    "print(\"Values for Best Parameters from Grid Search Linear Classifier : \",\"Precision ->\",Precision,\" Recall->\",Recall,\" F1score->\",F1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission Test Tweets Prep \n",
    "submissionDataPath = dataPath + \"test.csv\"\n",
    "submissionData = pd.read_csv(submissionDataPath,encoding='utf-8')\n",
    "\n",
    "\n",
    "submissionData['cleanedTweet'] = submissionData['tweet'].transform(apostropheCleaner)\n",
    "submissionData['cleanedTweet'] = submissionData['cleanedTweet'].transform(linkCleaner)\n",
    "submissionData['hastag'] = submissionData['cleanedTweet'].transform(hashtagExtract)\n",
    "submissionData['cleanedTweet'] = submissionData['cleanedTweet'].transform(wordCleaner)\n",
    "\n",
    "# retraining on complete original data with best parameters\n",
    "clf_bnb = clf_bnb.fit(features,label)\n",
    "\n",
    "# predicting the class for the test data\n",
    "submissionData['label'] =  clf_bnb.predict(submissionData['cleanedTweet'])\n",
    "submission = submissionData[[\"id\",\"label\"]].set_index(\"id\")\n",
    "\n",
    "# submissionData.describe()\n",
    "submission.to_csv(dataPath+\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
