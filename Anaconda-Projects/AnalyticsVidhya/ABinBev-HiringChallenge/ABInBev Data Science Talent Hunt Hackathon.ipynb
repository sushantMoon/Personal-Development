{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contest Link : https://datahack.analyticsvidhya.com/contest/data-science-talent-hunt-hackathon/\n",
    "Resources Used :\n",
    "1. [Product Model mentioned](https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting/discussion/8033)\n",
    "\n",
    "Reading Material\n",
    "1. https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting/discussion/8023\n",
    "2. https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting/discussion/8055\n",
    "3. https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting/discussion/8028\n",
    "4. https://www.kaggle.com/c/see-click-predict-fix/discussion/6466#35490\n",
    "5. https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting/discussion/8125\n",
    "6. https://bitbucket.org/dthal/kaggle_walmart/src/c7c8c81a6a52?at=master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = 'E:/GitHub/Personal-Development/Anaconda-Projects/AnalyticsVidhya/ABinBev-HiringChallenge/Data/train_data/'\n",
    "outputPath = 'E:/GitHub/Personal-Development/Anaconda-Projects/AnalyticsVidhya/ABinBev-HiringChallenge/Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateparse = lambda x: pd.datetime.strptime(x, '%Y%m')\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "demograhics = pd.read_csv(dataPath + 'demographics.csv')\n",
    "demograhics['Agency'] = demograhics['Agency'].apply(lambda x : int(x.split('_')[1]))\n",
    "# demograhics.describe()\n",
    "# demograhics.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# demograhics.plot(x='Agency',y='Avg_Yearly_Household_Income_2017')\n",
    "# demograhics.plot(x='Agency',y='Avg_Population_2017')\n",
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "demograhics.plot(x='Agency',secondary_y='Avg_Population_2017', ax=ax, kind='bar')\n",
    "\n",
    "ax.set_xlabel('Agency')\n",
    "ax.set_ylabel('Avg_Yearly_Household_Income_2017')\n",
    "ax.right_ax.set_ylabel('Avg_Population_2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "event_calendar = pd.read_csv(dataPath + 'event_calendar.csv', parse_dates=['YearMonth'], date_parser=dateparse)\n",
    "# event_calendar.all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(2)\n",
    "# event_calendar.plot(kind='bar' ,x='YearMonth' ,stacked=True)\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "\n",
    "event_calendar.plot(kind='bar', x='YearMonth', stacked=True, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_volume = pd.read_csv(dataPath + 'historical_volume.csv',parse_dates=['YearMonth'], date_parser=dateparse)\n",
    "historical_volume['Agency'] = historical_volume['Agency'].apply(lambda x : int(x.split('_')[1]))\n",
    "historical_volume['SKU'] = historical_volume['SKU'].apply(lambda x : int(x.split('_')[1]))\n",
    "# historical_volume.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(3)\n",
    "plt.style.use('ggplot')\n",
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "\n",
    "historical_volume.plot(ax=ax, x='YearMonth', y='Volume', kind='line')\n",
    "ax.set_ylabel('Volume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_soda_sales = pd.read_csv(dataPath + 'industry_soda_sales.csv',parse_dates=['YearMonth'], date_parser=dateparse)\n",
    "# industry_soda_sales.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(4)\n",
    "plt.style.use('ggplot')\n",
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "\n",
    "industry_soda_sales.plot(ax=ax, x='YearMonth', y='Soda_Volume', kind='line')\n",
    "ax.set_ylabel('Soda_Volume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_volume = pd.read_csv(dataPath + 'industry_volume.csv',parse_dates=['YearMonth'], date_parser=dateparse)\n",
    "# industry_volume.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(5)\n",
    "plt.style.use('ggplot')\n",
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "\n",
    "industry_volume.plot(ax=ax, x='YearMonth', y='Industry_Volume', kind='line')\n",
    "ax.set_ylabel('Industry_Volume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "price_sales_promotion = pd.read_csv(dataPath + 'price_sales_promotion.csv', parse_dates=['YearMonth'], date_parser=dateparse)\n",
    "price_sales_promotion['Agency'] = price_sales_promotion['Agency'].apply(lambda x : int(x.split('_')[1]))\n",
    "price_sales_promotion['SKU'] = price_sales_promotion['SKU'].apply(lambda x : int(x.split('_')[1]))\n",
    "# price_sales_promotion.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(5)\n",
    "plt.style.use('ggplot')\n",
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "\n",
    "price_sales_promotion.plot(ax=ax, x='YearMonth', kind='line')\n",
    "# ax.set_ylabel('Avg Max Temparature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv(dataPath + 'weather.csv',parse_dates=['YearMonth'], date_parser=dateparse)\n",
    "weather['Agency'] = weather['Agency'].apply(lambda x : int(x.split('_')[1]))\n",
    "# weather.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(7)\n",
    "plt.style.use('ggplot')\n",
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "\n",
    "weather.plot(ax=ax, x='YearMonth', y='Avg_Max_Temp', kind='line')\n",
    "ax.set_ylabel('Avg Max Temparature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Merging of data into single Training Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "####### Command used to look for NANs #######\n",
    "# merge1 = pd.merge(historical_volume,event_calendar,on='YearMonth',how='outer',indicator=True)\n",
    "# # data = merge1[merge1['_merge'] != 'both']\n",
    "# # data.all\n",
    "merge1 = pd.merge(historical_volume,event_calendar,on='YearMonth',how='outer')\n",
    "# event calender has data for the month of 2018-01-01 (2018 Jan)\n",
    "# one last row is has null data for agency and sku n volume part, hence dropping\n",
    "merge1 = merge1.drop(21000,axis=0)\n",
    "# merge1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merge2 = pd.merge(merge1,weather,on=['YearMonth','Agency'],how='outer',indicator=True)\n",
    "# weather has data for Agency 14 and Agency 6\n",
    "merge2 = merge2[merge2['_merge'] == 'both']\n",
    "merge2 = merge2.drop(['_merge'],axis=1)\n",
    "# merge2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# merge3 = pd.merge(merge2,price_sales_promotion,on=['Agency','SKU','YearMonth'],how='outer',indicator=True)\n",
    "merge3 = pd.merge(merge2,price_sales_promotion,on=['Agency','SKU','YearMonth'],how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# merge4 = pd.merge(merge3,industry_volume,on=['YearMonth'],how='outer',indicator=True)\n",
    "merge4 = pd.merge(merge3,industry_volume,on=['YearMonth'],how='outer')\n",
    "# merge4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# merge5 = pd.merge(merge4,industry_soda_sales,on=['YearMonth'],how='outer',indicator=True)\n",
    "merge5 = pd.merge(merge4,industry_soda_sales,on=['YearMonth'],how='outer')\n",
    "# merge5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agency</th>\n",
       "      <th>SKU</th>\n",
       "      <th>YearMonth</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Easter Day</th>\n",
       "      <th>Good Friday</th>\n",
       "      <th>New Year</th>\n",
       "      <th>Christmas</th>\n",
       "      <th>Labor Day</th>\n",
       "      <th>Independence Day</th>\n",
       "      <th>...</th>\n",
       "      <th>Beer Capital</th>\n",
       "      <th>Music Fest</th>\n",
       "      <th>Avg_Max_Temp</th>\n",
       "      <th>Price</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Promotions</th>\n",
       "      <th>Industry_Volume</th>\n",
       "      <th>Soda_Volume</th>\n",
       "      <th>Avg_Population_2017</th>\n",
       "      <th>Avg_Yearly_Household_Income_2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>52.2720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.845238</td>\n",
       "      <td>1168.903668</td>\n",
       "      <td>1069.166193</td>\n",
       "      <td>99.737475</td>\n",
       "      <td>492612703.0</td>\n",
       "      <td>718394219.0</td>\n",
       "      <td>48151</td>\n",
       "      <td>132110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>110.7000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.845238</td>\n",
       "      <td>1167.000000</td>\n",
       "      <td>1067.257500</td>\n",
       "      <td>99.742500</td>\n",
       "      <td>492612703.0</td>\n",
       "      <td>718394219.0</td>\n",
       "      <td>48151</td>\n",
       "      <td>132110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>238.5387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.845238</td>\n",
       "      <td>1310.176057</td>\n",
       "      <td>1203.875711</td>\n",
       "      <td>106.300346</td>\n",
       "      <td>492612703.0</td>\n",
       "      <td>718394219.0</td>\n",
       "      <td>48151</td>\n",
       "      <td>132110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>31.0554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.845238</td>\n",
       "      <td>1742.112676</td>\n",
       "      <td>1598.414189</td>\n",
       "      <td>143.698487</td>\n",
       "      <td>492612703.0</td>\n",
       "      <td>718394219.0</td>\n",
       "      <td>48151</td>\n",
       "      <td>132110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>86.4612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.845238</td>\n",
       "      <td>1258.729104</td>\n",
       "      <td>1156.645866</td>\n",
       "      <td>102.083238</td>\n",
       "      <td>492612703.0</td>\n",
       "      <td>718394219.0</td>\n",
       "      <td>48151</td>\n",
       "      <td>132110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Agency SKU  YearMonth    Volume  Easter Day  Good Friday  New Year  \\\n",
       "0    22.0   1 2013-01-01   52.2720         0.0          0.0       1.0   \n",
       "1    22.0   2 2013-01-01  110.7000         0.0          0.0       1.0   \n",
       "2    22.0   5 2013-01-01  238.5387         0.0          0.0       1.0   \n",
       "3    22.0   4 2013-01-01   31.0554         0.0          0.0       1.0   \n",
       "4    22.0   3 2013-01-01   86.4612         0.0          0.0       1.0   \n",
       "\n",
       "   Christmas  Labor Day  Independence Day                ...                 \\\n",
       "0        0.0        0.0               0.0                ...                  \n",
       "1        0.0        0.0               0.0                ...                  \n",
       "2        0.0        0.0               0.0                ...                  \n",
       "3        0.0        0.0               0.0                ...                  \n",
       "4        0.0        0.0               0.0                ...                  \n",
       "\n",
       "   Beer Capital  Music Fest  Avg_Max_Temp        Price        Sales  \\\n",
       "0           0.0         0.0     25.845238  1168.903668  1069.166193   \n",
       "1           0.0         0.0     25.845238  1167.000000  1067.257500   \n",
       "2           0.0         0.0     25.845238  1310.176057  1203.875711   \n",
       "3           0.0         0.0     25.845238  1742.112676  1598.414189   \n",
       "4           0.0         0.0     25.845238  1258.729104  1156.645866   \n",
       "\n",
       "   Promotions  Industry_Volume  Soda_Volume  Avg_Population_2017  \\\n",
       "0   99.737475      492612703.0  718394219.0                48151   \n",
       "1   99.742500      492612703.0  718394219.0                48151   \n",
       "2  106.300346      492612703.0  718394219.0                48151   \n",
       "3  143.698487      492612703.0  718394219.0                48151   \n",
       "4  102.083238      492612703.0  718394219.0                48151   \n",
       "\n",
       "   Avg_Yearly_Household_Income_2017  \n",
       "0                            132110  \n",
       "1                            132110  \n",
       "2                            132110  \n",
       "3                            132110  \n",
       "4                            132110  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData = pd.merge(merge5,demograhics,on=['Agency'],how='outer', indicator=True)\n",
    "# demographics has data for the Agency 14 and Agency 6 \n",
    "trainData = trainData[trainData['_merge'] == 'both']\n",
    "trainData = trainData.drop(['_merge'],axis=1)\n",
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescaling the high value columns\n",
    "trainData[['Avg_Max_Temp','Price','Sales','Promotions','Industry_Volume','Soda_Volume','Avg_Population_2017','Avg_Yearly_Household_Income_2017']] = scaler.fit_transform(trainData[['Avg_Max_Temp','Price','Sales','Promotions','Industry_Volume','Soda_Volume','Avg_Population_2017','Avg_Yearly_Household_Income_2017']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for checking any correlation between  columns\n",
    "correlation = trainData.corr(method = 'pearson')\n",
    "# correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the bell curve / normal distribution of the data \n",
    "skew = trainData.skew()\n",
    "# skew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Following are the calculations done using the Product Model :\n",
    "\n",
    "Predicted Avg Volume = (Avg. Volume per agency over Months * Avg. Volume per Month over Agencies)/Avg Volume per SKU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Avg Volumne for each SKU\n",
    "sku = trainData.groupby(['SKU'])['Volume'].mean().reset_index()\n",
    "# sku.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Per-month Avg Volumne for each SKU (the avg is done over agencies)\n",
    "sku_month = trainData.groupby(['SKU',trainData['YearMonth'].dt.month])['Volume'].mean().reset_index()\n",
    "# for calculating avg forthe month of january , extracting data for january for all the SKU's\n",
    "sku_month_jan = sku_month[sku_month['YearMonth'] == 1]\n",
    "# sku_month_jan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Per-Agency Avg Volumne for each SKU (the avg is done over month)\n",
    "sku_agency = trainData.groupby(['SKU','Agency'])['Volume'].mean().reset_index()\n",
    "# sku_agency.head()\n",
    "# sku_agency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "sku_agency_jan = pd.merge(sku_agency,sku_month_jan, on=['SKU'], how= 'outer')\n",
    "# sku_agency_jan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "sku_agency_jan_sku_avg = pd.merge(sku_agency_jan,sku, on=['SKU'], how= 'outer')\n",
    "# sku_agency_jan_sku_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "sku_agency_jan_sku_avg['PredictedVolume'] = (sku_agency_jan_sku_avg['Volume_x'] * sku_agency_jan_sku_avg['Volume_y'])/sku_agency_jan_sku_avg['Volume']\n",
    "sku_agency_predicted = sku_agency_jan_sku_avg.drop(['YearMonth','Volume','Volume_x','Volume_y'], axis = 1)\n",
    "sku_agency_predicted.to_csv(outputPath+'calculated_volume_forcast.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
