{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "    Mercari monitors its marketplace 24/7/365 for listings with prohibited items.\n",
    "    \n",
    "    Suppose that someone in the company created a new algorithm for automatically detecting these prohibited listings. This algorithm is shown to be 99.9% accurate. It is now your job to evaluate the validity and practicality of the algorithm. What sort of evaluations do you think are necessary?\n",
    "    Feel free to list up multiple examples if you have more than one, but be sure to order them in terms of priority. Assume that the algorithm itself is implemented correctly and there are no bugs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution\n",
    "\n",
    "\n",
    " ## Following are the points for Validity of the model\n",
    " \n",
    " Considering that the model is build on certain size dataset which was present with the company. This dataset may not be the complete population.\n",
    " \n",
    " Now for testing the validity of the model, we would need to test it on more unseen data. If the prediction accuracy holds then we are safe to infer that the model is a good fit, but if the accuracy suffers then there might be problems at following two places :\n",
    "     \n",
    "     1. Model : It might be overfitting the training data\n",
    "     \n",
    "     2. Training data : It may not be the actual representation of the distribution of the complete population and there might be certain bias in the training data itself. \n",
    "  \n",
    "  Now one of the method to check for validity, would be to have controlled roll out of the model. Now in controlled roll out, model would be tested against new data in incremental phases. If our generalization error remains low we say that our model has achieved a good fit, else we would have the above two mentioned problems. In low generalization error, we retrain the model with complete available data and roll out the model to the next phase. \n",
    "  \n",
    "  \n",
    " ## Following are the points for Practicality of the model \n",
    " \n",
    " If given a model with 99.99% accuracy, we should be evaluating it now with respect to the following criteria :\n",
    "    \n",
    "    1. Time to make the prediction\n",
    "\n",
    "    2. Cost and Hardware requirements for the prediction\n",
    "\n",
    "    3. Scalability of the model\n",
    "\n",
    "    4. Usability of the model\n",
    "\n",
    "    5. Transferability of the learning from the model\n",
    "\n",
    "    6. Maintainance and Support\n",
    "\n",
    " Note that we would be keeping in mind the following thing : \n",
    " \n",
    "    a. Mercari monitors its marketplace 24/7/365 for listings with prohibited items.\n",
    " \n",
    "    b. As the company is popular, it's listing size is growing each passing day.\n",
    "\n",
    " Now details on our evaluation criteria :\n",
    "\n",
    "\n",
    "    1. Time to make the prediction :\n",
    "    \n",
    "            The actual time required by the model to predict any given listing, if this time required is in days then it is no better than a person doing the same job on his own. Hence for the practicality of the model, this time should be very small (a minute at the most, if not seconds or anything lower).\n",
    "\n",
    "            Eg. K-means is slow for running on production.\n",
    "            \n",
    "            Evaluating whether a listing is prohibited may be handled in :\n",
    "\n",
    "            a. Real Time i.e. as soon as the listing is added in the system it is processed for prohibited listing.\n",
    "            b. Batch Processing i.e all the new listing are checked for prohibited listing in batch at the end of the day.\n",
    "\n",
    "            It should be noted that, atleast the average amount of new listings generated on daily basis should be processed within that day itself and no backlog should be generated\n",
    "\n",
    "\n",
    "    2. Cost and Hardware requirements for the prediction :\n",
    "    \n",
    "            Any cost associated with a running model for a prolonged time is considered heavy. Also, any hardware required by the model is directly added to this cost.\n",
    "            \n",
    "            Though training a model, in general, requires hardware of high specs, this is a one-time cost and is more practical to bear. If the hardware requirements for running this model at the time of making a prediction is also high then it narrows down the practical usability of the model.\n",
    "            \n",
    "            Eg. a. Assuming properties or definition of the prohibited listing items do not change over time, we do have an option to deploy the model on the client machines directly as the model itself would not have to be updated frequently. Now in that case the model should be able to run and predict the listing on hardware which is as cheap as mobile.\n",
    "                b. If the defination prohibited items evolves with time and its properties changes, then retraining would be required and the prediction should be made on the server side only.\n",
    "                \n",
    "                Now both of the above cases should not come at the expense of end-user's user-experience.\n",
    "                \n",
    "            In an ideal scenario, we would want to lower the costs and hardware requirements at training as well as at the time of predicting.  \n",
    "\n",
    "\n",
    "    3. Scalability of the model :\n",
    "\n",
    "            Any model which is scalable horizontally and well as vertically is desired.\n",
    "            \n",
    "            By scaling horizontally, it means, can the model run in a distributed environment, can it take advantage of the existing distrubuted technology. Many smaller specs machines running together can also give computational power equivalent to a machine with high specs. Also, multiple machines with lower specs can be much cheaper than a single machine with higher specs.\n",
    "            \n",
    "            By scaling vertically, it means, would the performance, run time of the model improve with a higher spec machine.\n",
    "            It is worth mentioning that in this age of distributed computing having a model which scales horizontally is much more desirable.\n",
    "\n",
    "\n",
    "    4. Usability of the model:\n",
    "\n",
    "            As this model is going to run continuously on an ever-increasing dataset, it is desirable that the model is as developer friendly as possible. Due to its requirement to run 24/7/365, it would be great that any developer can deploy it any time with minimal effort. The default parameters should be such that it works out of the box. We should not be needing specialized person just to run the model.\n",
    "            \n",
    "            Eg. If a new pipeline is to be deployed, now a specialized person should not have to be reloacted just for the sake of deploying the model.\n",
    "\n",
    "\n",
    "    5. Maintainance and Support\n",
    "\n",
    "            The model should be able to run for longer durations with no or relatively very less maintenance and support. It is desired from the model that no human intervention would be required even after the prolonged running of the model.\n",
    "            Now with our assumption if the prohibited listing defination does not change, we may or may not have to retrain the model. But if the defination changes then, after every set interval we would have to update the model to take into the account the changes in defination.\n",
    "            \n",
    "            Eg. Suppose the defination of the prohibited listing items evolves over time and certain listings phase out and new listings come in, it would be advisable to retrain/fine-tune the model on the new/updated dataset.\n",
    "\n",
    "\n",
    "    6. Transferability of the learning from the model\n",
    "\n",
    "            By transferability of learning of the model, it means that, would it be possible for us to take the key concepts and learnings from this model and apply to other problems that the company faces. Can these learnings be generalized? If yes then it would be very much beneficial for the company. \n",
    "            \n",
    "            Any model which is able to generalize well over many different problems is worth investing one's time and efforts into and a lot of people would be interested in it, which can lead to an open source community of researchers and developers build around it. This would, in turn, help the company to attract a lot of talented individuals. If that is not in the options, then patenting it can also be a good idea.\n",
    "            \n",
    "            Eg. Inception (Deep Learning Model which classifies images) can be retrained for a new class of images with relatively less amount. \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
